---
title: Technova ML API
emoji: ü§ñ
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
pinned: false
---

# Technova ML API

## Sommaire
- [Pr√©sentation du projet](#pr√©sentation-du-projet)
- [Structure du projet](#structure-du-projet)
- [Architecture globale](#architecture-globale)
- [Int√©gration Continue et D√©ploiement Continu](#int√©gration-continue-et-d√©ploiement-continu)
- [Architecture des donn√©es (BDD)](#architecture-des-donn√©es-bdd)
- [Mod√®le de Machine Learning](#mod√®le-de-machine-learning)
- [API FastAPI](#api-fastapi)
- [S√©curit√© et authentification](#s√©curit√©-et-authentification)
- [Audit et tra√ßabilit√©](#audit-et-tra√ßabilit√©)
- [Tests et qualit√© du code](#tests-et-qualit√©-du-code)
- [D√©ploiement](#d√©ploiement)
- [Installation et utilisation](#installation-et-utilisation)


---

## Pr√©sentation du projet

**Technova ML API** est une API de pr√©diction d‚Äôattrition des employ√©s bas√©e sur un mod√®le de Machine Learning.
Elle permet de pr√©dire la probabilit√© de d√©part d‚Äôun employ√© √† partir de donn√©es RH structur√©es.

---

## Structure du projet

Le d√©p√¥t est organis√© de mani√®re modulaire afin de s√©parer
les responsabilit√©s (API, ML, base de donn√©es, tests).

```text
technova-ml-api/
‚îú‚îÄ app/
‚îÇ  ‚îú‚îÄ main.py              # Point d‚Äôentr√©e de l‚ÄôAPI FastAPI
‚îÇ  ‚îú‚îÄ core/                # Configuration et settings
‚îÇ  ‚îú‚îÄ security/            # Authentification (API Key)
‚îÇ  ‚îú‚îÄ ml/                  # Chargement du mod√®le et pr√©dictions
‚îÇ  ‚îú‚îÄ services/            # Logique m√©tier (predict, audit)
‚îÇ  ‚îú‚îÄ db/                  # Connexion DB et scripts SQL
‚îÇ  ‚îî‚îÄ schemas/             # Sch√©mas Pydantic (entr√©es/sorties)
‚îÇ
‚îú‚îÄ db/
‚îÇ  ‚îú‚îÄ schema.sql           # Cr√©ation des sch√©mas PostgreSQL
‚îÇ  ‚îú‚îÄ raw.sql              # Tables de donn√©es brutes
‚îÇ  ‚îú‚îÄ staging.sql          # Nettoyage et transformations
‚îÇ  ‚îú‚îÄ mart.sql             # Dataset final pour le mod√®le ML
‚îÇ  ‚îî‚îÄ audit.sql            # Journalisation des pr√©dictions
‚îÇ
‚îú‚îÄ tests/                  # Tests unitaires et fonctionnels (Pytest)
‚îÇ
‚îú‚îÄ .github/workflows/      # Pipeline CI (tests automatiques)
‚îú‚îÄ requirements.txt
‚îî‚îÄ README.md
```
---

## Architecture globale

- API d√©velopp√©e avec **FastAPI**
- Base de donn√©es **PostgreSQL**
- Mod√®le ML entra√Æn√© en amont (hors API), puis charg√© au d√©marrage de l‚Äôapplication
- D√©ploiement local et sur **Hugging Face Spaces**
- S√©curit√© par **API Key**
- Tests automatis√©s avec **Pytest**



---
## Int√©gration Continue et D√©ploiement Continu

Le projet int√®gre une d√©marche d‚Äôint√©gration continue (CI) afin de garantir
la qualit√© et la stabilit√© du code √† chaque modification.
Les mises √† jour du code ou du mod√®le sont r√©alis√©es via des commits sur la branche principale,
d√©clenchant automatiquement les tests et le red√©ploiement de l‚ÄôAPI gr√¢ce au pipeline CI/CD.

### Int√©gration Continue (CI)
- Pipeline automatis√© via **GitHub Actions**
- Ex√©cution des tests Pytest √† chaque push et pull request
- Validation du code avant fusion sur la branche principale
- D√©tection pr√©coce des r√©gressions

### D√©ploiement Continu (CD)
- D√©ploiement de l‚ÄôAPI sur **Hugging Face Spaces**
- Gestion des secrets (API Key, acc√®s mod√®le) via variables d‚Äôenvironnement
- S√©paration des environnements (local / CI / production)

Cette approche permet un d√©ploiement fiable, reproductible et s√©curis√©
du mod√®le de Machine Learning expos√© par l‚ÄôAPI.

---

## Architecture des donn√©es (BDD)

Les d√©tails techniques concernant la base de donn√©es
(sch√©mas, tables, scripts SQL et pipeline de transformation)
sont document√©s dans `db/README_SQL.md`.

Le sch√©ma ci-dessous pr√©sente le flux logique des donn√©es,
de l‚Äôingestion jusqu‚Äô√† l‚Äôaudit des pr√©dictions.

### Pipeline de donn√©es

```mermaid
flowchart TD
    RAW[RAW<br/>Donn√©es brutes]
    RAW_SIRH[extrait_sirh]
    RAW_EVAL[extrait_eval]
    RAW_SONDAGE[extrait_sondage]

    STAGING[STAGING<br/>Nettoyage & normalisation]
    STAGING_EMP[employee_base]

    MART[MART<br/>Dataset ML]
    MART_EMP[employee_features]

    AUDIT[AUDIT<br/>Tra√ßabilit√© API]
    AUDIT_REQ[prediction_requests]
    AUDIT_RES[prediction_responses]

    RAW --> RAW_SIRH
    RAW --> RAW_EVAL
    RAW --> RAW_SONDAGE

    RAW_SIRH --> STAGING
    RAW_EVAL --> STAGING
    RAW_SONDAGE --> STAGING

    STAGING --> STAGING_EMP
    STAGING_EMP --> MART
    MART --> MART_EMP

    MART_EMP -->|utilis√© par le mod√®le ML| AUDIT
    AUDIT --> AUDIT_REQ
    AUDIT --> AUDIT_RES
```

### Description des sch√©mas

- **RAW** : donn√©es brutes sans transformation.
- **STAGING** : nettoyage, normalisation et jointure des sources.
- **MART** : dataset final utilis√© par le mod√®le ML.
- **AUDIT** : tra√ßabilit√© compl√®te des appels API et des pr√©dictions.

---

## Mod√®le de Machine Learning

- Type : classification binaire
- Cible : d√©part de l‚Äôemploy√©
- Sortie : probabilit√© + d√©cision selon un seuil configurable
- Seuil stock√© dans un fichier de configuration


Les performances du mod√®le ont √©t√© √©valu√©es en amont lors du projet de data science,
et le mod√®le est ici r√©utilis√© comme un composant valid√© pour un usage en production.
---

## API FastAPI

### Endpoints principaux

- `GET /health` : √©tat de l‚ÄôAPI
- `POST /predict` : pr√©diction √† partir de donn√©es fournies
- `GET /predict/{id_employee}` : pr√©diction √† partir de la base de donn√©es

La documentation est disponible via Swagger :
`/docs`

---
### Exemple POST /predict

```json
{
  "age": 41,
  "genre": "femme",
  "revenu_mensuel": 5993,
  "statut_marital": "c√©libataire",
  "departement": "commercial",
  "poste": "cadre commercial",
  "nombre_experiences_precedentes": 8,
  "annees_dans_l_entreprise": 2,
  "satisfaction_employee_environnement": 4,
  "satisfaction_employee_nature_travail": 1,
  "satisfaction_employee_equipe": 1,
  "satisfaction_employee_equilibre_pro_perso": 1,
  "heure_supplementaires": True,
  "augmentation_salaire_precedente": 11,
  "nombre_participation_pee": 0,
  "nb_formations_suivies": 0,
  "distance_domicile_travail": 1,
  "niveau_education": 2,
  "domaine_etude": "infra & cloud",
  "frequence_deplacement": "occasionnel",
  "annees_sous_responsable_actuel": 0,
  "annees_dans_le_poste_actuel": 0,
  "note_evaluation_actuelle": 0,
  "note_evaluation_precedente": 0,
  "annees_depuis_la_derniere_promotion": 0
}
```
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -H "X-API-Key: <YOUR_API_KEY>" \
  -d @payload.json
  ```

### Exemple GET /predict/7

Pr√©diction √† partir des donn√©es stock√©es pour l‚Äôemploy√© d‚Äôidentifiant 7.

---

## S√©curit√© et authentification

- Protection des endpoints sensibles via **API Key**
- Cl√© transmise dans le header : `X-API-Key`
- Gestion des secrets via variables d‚Äôenvironnement
- Compatible CI/CD et Hugging Face Spaces

---

## Audit et tra√ßabilit√©

Chaque appel de pr√©diction est enregistr√© :

- **prediction_requests** : payload d‚Äôentr√©e
- **prediction_responses** : probabilit√©, d√©cision, seuil

Cette approche garantit la reproductibilit√© et l‚Äôauditabilit√© des pr√©dictions.

---

## Tests et qualit√© du code

- Tests unitaires et fonctionnels avec **Pytest**
- Tests de s√©curit√© (API Key)
- Tests des endpoints critiques
- Ex√©cution automatis√©e en CI

---

## D√©ploiement

- D√©ploiement local (Python)
- D√©ploiement cloud sur Hugging Face Spaces
- Gestion des secrets via variables d‚Äôenvironnement

Lien de l‚ÄôAPI d√©ploy√©e :
https://huggingface.co/spaces/donizetti-yoann/technova-ml-api

---

## Variables d‚Äôenvironnement

Les variables suivantes sont n√©cessaires au fonctionnement de l‚ÄôAPI :

- `API_KEY` : cl√© d‚Äôauthentification des endpoints
- `DATABASE_URL` : cha√Æne de connexion PostgreSQL
- `MODEL_PATH` : chemin vers le mod√®le local (optionnel)
- `HF_MODEL_REPO` / `HF_MODEL_FILENAME` : mod√®le h√©berg√© sur Hugging Face
- `HF_TOKEN` : token Hugging Face (si requis)

Ces variables sont fournies via l‚Äôenvironnement d‚Äôex√©cution
(local, CI/CD ou Hugging Face Spaces) et ne sont jamais stock√©es
en clair dans le d√©p√¥t.
---

## Installation et utilisation

```bash
git clone https://github.com/yoann-donizetti/technova-ml-api
cd technova-ml-api
pip install -r requirements.txt
uvicorn app.main:app --reload
```

---
